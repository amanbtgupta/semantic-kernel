{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Reporter Agentic System Using Semantic Kernel SDK and Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing important libraries and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "import os\n",
    "import asyncio\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import BingGroundingTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_MODEL\")\n",
    "ai_project_connection_string = os.getenv(\"AI_PROJECT_CONNECTION_STRING\")\n",
    "bing_connection_name = os.getenv(\"BING_CONNECTION_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an Azure AI Project Client to connect to Azure AI Agent Service (AI Foundry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=ai_project_connection_string\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an \"Agent\" Plugin Class which will include native plugins to be fed into the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agents:\n",
    "    @kernel_function(\n",
    "        description=\"This function will be used to use an azure ai agent with web grounding capability using Bing Search API\",\n",
    "        name=\"WebSearchAgent\"\n",
    "    )\n",
    "    def web_search_agent(\n",
    "        self,\n",
    "        query: Annotated[str, \"The user query for which the contextual information needs to be fetched from the web\"]\n",
    "        \n",
    "    ) -> Annotated[str, \"The response from the web search agent\"]:\n",
    "        bing_connection = project_client.connections.get(connection_name=bing_connection_name)\n",
    "        conn_id = bing_connection.id\n",
    "        bing = BingGroundingTool(connection_id=conn_id)\n",
    "        \n",
    "        agent = project_client.agents.create_agent(\n",
    "        model=azure_openai_deployment_name,\n",
    "            name=\"bing-assistant\",\n",
    "            instructions=\"You are a helpful assistant\",\n",
    "            tools=bing.definitions,\n",
    "            headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        )\n",
    "        \n",
    "        thread = project_client.agents.create_thread()\n",
    "            \n",
    "        message = project_client.agents.create_message(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=query,\n",
    "            )\n",
    "            \n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "            \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        \n",
    "        print(\"Response from the web search agent:\")\n",
    "        print(\"\\n\")\n",
    "        print(messages.data[0].content[0].text.value)\n",
    "            \n",
    "        return messages.data[0].content[0].text.value\n",
    "       \n",
    "    \n",
    "    @kernel_function(\n",
    "       description=\"This function will use an azure ai agent to prepare a script for a news reporter based on latest information for a specific topic\",\n",
    "         name=\"NewsReporterAgent\"\n",
    "   )\n",
    "    def news_reporter_agent(\n",
    "        self,\n",
    "        topic: Annotated[str, \"The topic for which the latest information/news has been fetched\"],\n",
    "        latest_news: Annotated[str,\"The latest information for a specific topic\"]\n",
    "    ) -> Annotated[str, \"the response from the NewsReporterAgent which is the script for a news reporter\"]:\n",
    "\n",
    "        agent = project_client.agents.create_agent(\n",
    "        model=azure_openai_deployment_name,\n",
    "        name=\"news-reporter\",\n",
    "        instructions=\"\"\"You are a helpful assistant that is meant to prepare a script for a news reporter based on the latest information for a specific topic both of which you will be given.\n",
    "            The news channel is named MSinghTV and the news reporter is named John. You will be given the topic and the latest information for that topic. Prepare a script for the news reporter John based on the latest information for the topic.\"\"\",\n",
    "            headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        )\n",
    "        \n",
    "        thread = project_client.agents.create_thread()\n",
    "            \n",
    "        message = project_client.agents.create_message(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=f\"\"\"The topic is {topic} and the latest information is {latest_news}\"\"\",\n",
    "            )\n",
    "            \n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "            \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        \n",
    "        print(\"Script for the news reporter:\")\n",
    "        print(\"\\n\")    \n",
    "        print(messages.data[0].content[0].text.value)\n",
    "            \n",
    "        return messages.data[0].content[0].text.value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Kernel of the Semantic Kernel SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"default\"\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(service_id=service_id,\n",
    "                        api_key=azure_openai_key,\n",
    "                        deployment_name=azure_openai_deployment_name,\n",
    "                        endpoint = azure_openai_endpoint\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Our Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = SequentialPlanner(\n",
    "    kernel,\n",
    "    service_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the Agentic Plugins as native plugins to our Kernel so created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_plugin = kernel.add_plugin(Agents(), \"Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = f\"prepare a news script for John on latest news for the world?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoking the Planner and printing its steps/thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plan's steps are:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute '_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sequential_plan \u001b[38;5;241m=\u001b[39m  call_planner()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe plan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms steps are:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[43msequential_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mstep\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo description\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mfully_qualified_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute '_steps'"
     ]
    }
   ],
   "source": [
    "async def call_planner():\n",
    "    return await planner.create_plan(goal)\n",
    "\n",
    "sequential_plan = await call_planner()\n",
    "\n",
    "print(\"The plan's steps are:\")\n",
    "for step in sequential_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the \"Plan\" generated by the Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some recent highlights from world news:\n",
      "\n",
      "1. **Political Developments**: US President Donald Trump has initiated negotiations to end the Ukraine conflict following a conversation with Russian President Vladimir Putin. Meanwhile, Tulsi Gabbard has been confirmed as the director of national intelligence in Trump's administration, amidst controversy regarding her past positions【4†source】.\n",
      "\n",
      "2. **Scientific Phenomena**: An unusual natural occurrence was observed in Austria, where a skier came across a column of light during a snowstorm, creating an impression of a 'portal to another world'【1†source】.\n",
      "\n",
      "These stories reflect a mix of political news and intriguing natural phenomena making waves currently.\n",
      "**Script for John at MSinghTV**\n",
      "\n",
      "---\n",
      "\n",
      "**[Camera focuses on John at the MSinghTV studio desk]**\n",
      "\n",
      "**John:** \n",
      "\n",
      "Good evening, I'm John, reporting for MSinghTV, bringing you the latest updates from around the world.\n",
      "\n",
      "Tonight, we start with a significant political development that could reshape the global landscape. In a surprising move, US President Donald Trump has initiated talks aimed at resolving the ongoing conflict in Ukraine. This follows a direct conversation with Russian President Vladimir Putin. The international community is watching closely, as these negotiations could potentially lead to a peaceful resolution in a region marked by prolonged instability and conflict.\n",
      "\n",
      "In another political update, the Trump administration has named Tulsi Gabbard as the new director of national intelligence. Gabbard's appointment has sparked controversy, given her previous positions and statements, but the administration believes she brings a fresh perspective to the role at this crucial time.\n",
      "\n",
      "Shifting gears to a fascinating scientific phenomenon, an unusual and ethereal event unfolded in the mountains of Austria. A skier witnessed what appeared to be a 'portal to another world' when a column of light emerged during a snowstorm. This striking natural occurrence has sparked curiosity and wonder, capturing imaginations and prompting scientific inquiry into similar atmospheric phenomena.\n",
      "\n",
      "These stories illustrate the complex tapestry of global affairs, from political shifts to the awe-inspiring power of nature.\n",
      "\n",
      "Stay tuned with us at MSinghTV for more news updates.\n",
      "\n",
      "**[Camera fades out as MSinghTV logo appears]**\n",
      "\n",
      "---\n",
      "\n",
      "That's all from me tonight. I'm John, wishing you a good evening and reminding you to stay informed and inspired.\n",
      "**Script for John at MSinghTV**\n",
      "\n",
      "---\n",
      "\n",
      "**[Camera focuses on John at the MSinghTV studio desk]**\n",
      "\n",
      "**John:** \n",
      "\n",
      "Good evening, I'm John, reporting for MSinghTV, bringing you the latest updates from around the world.\n",
      "\n",
      "Tonight, we start with a significant political development that could reshape the global landscape. In a surprising move, US President Donald Trump has initiated talks aimed at resolving the ongoing conflict in Ukraine. This follows a direct conversation with Russian President Vladimir Putin. The international community is watching closely, as these negotiations could potentially lead to a peaceful resolution in a region marked by prolonged instability and conflict.\n",
      "\n",
      "In another political update, the Trump administration has named Tulsi Gabbard as the new director of national intelligence. Gabbard's appointment has sparked controversy, given her previous positions and statements, but the administration believes she brings a fresh perspective to the role at this crucial time.\n",
      "\n",
      "Shifting gears to a fascinating scientific phenomenon, an unusual and ethereal event unfolded in the mountains of Austria. A skier witnessed what appeared to be a 'portal to another world' when a column of light emerged during a snowstorm. This striking natural occurrence has sparked curiosity and wonder, capturing imaginations and prompting scientific inquiry into similar atmospheric phenomena.\n",
      "\n",
      "These stories illustrate the complex tapestry of global affairs, from political shifts to the awe-inspiring power of nature.\n",
      "\n",
      "Stay tuned with us at MSinghTV for more news updates.\n",
      "\n",
      "**[Camera fades out as MSinghTV logo appears]**\n",
      "\n",
      "---\n",
      "\n",
      "That's all from me tonight. I'm John, wishing you a good evening and reminding you to stay informed and inspired.\n"
     ]
    }
   ],
   "source": [
    "async def generate_answer():\n",
    "    return await sequential_plan.invoke(kernel)\n",
    "\n",
    "result = await generate_answer()\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
